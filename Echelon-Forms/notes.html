<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-09-05 Thu 10:56 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Echelon Forms</title>
<meta name="author" content="Nathan  Mull" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="../myStyle.css" />
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'left',
      displayIndent: '2em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'left',
      displayIndent: '2em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="org-div-home-and-up"><a href="../toc.html">↩</a></div><div id="content" class="content">
<h1 class="title">Echelon Forms</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org04f3ca4">Recap: Linear Systems with Unique Solutions</a></li>
<li><a href="#orgce02c93">Echelon Form</a></li>
<li><a href="#orgfe6185c">Row-Reduced Echelon Form</a></li>
<li><a href="#orge3dcedd">General form solutions</a></li>
</ul>
</div>
</div>
<p>
In the next chapter, we'll look at <i>Gaussian elimination</i>, an algorithm
which can be used to solve systems of linear equations.  This is
arguably the most important topic for the first part of the course.
</p>

<p>
That said, I think the best way to understand Gaussian elimination is
from the punchline: Gaussian elimination converts any matrix into a
<b>unique row-equivalent matrix in row-reduced echelon form</b> (RREF).
RREF matrices are interesting because it's very easy to "read off"
their solutions, no matter whether there are no solutions, one unique
solution, or infinitely many solutions.<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>  In other
words, RREF matrices constitute the "final matrices" that "represent
solutions" which were hinted at in the previous chapter.
</p>

<p>
So before discussing how to solve systems of linear equations in
general, we'll take one more scheduled detour to look at "solving"
this particularly simple class of linear systems, i.e., those with
RREF augmented matrices.<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>
</p>

<div id="outline-container-org04f3ca4" class="outline-2">
<h2 id="org04f3ca4">Recap: Linear Systems with Unique Solutions</h2>
<div class="outline-text-2" id="text-org04f3ca4">
<p>
We've already seen what the "final matrix" look like when we're trying
to solve a linear system in \(n\) variables with unique solution. It's
an \(n \times (n + 1)\) matrix of the form:
</p>

\begin{bmatrix}
1 & 0 & \dots & 0 & b_1 \\
0 & 1 & \dots & 0 & b_2 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & \dots & 1 & b_n
\end{bmatrix}

<p>
which represents the linear system
</p>

\begin{align*}
x_1 &= b_1 \\
x_2 &= b_2 \\
&\vdots \\
x_n &= b_n
\end{align*}

<p>
which has a unique solution \((b_1, b_2, \dots, b_n)\).  In other words,
it's a system whose <i>coefficient</i> matrix has \(1\) entries along the
diagonal and \(0\) entries everywhere else.<sup><a id="fnr.3" class="footref" href="#fn.3" role="doc-backlink">3</a></sup>  <i>The
point:</i> it's very easy to "read off" what the solution is in this
system, so if we can reduce a matrix to this form, then we can read
off its unique solution easily.
</p>

<p>
But not all matrices can be reduced to a form like this.  First off,
the shape might not be right: if the augmented matrix of a system is
\(2 \times 7\), we can't somehow end up with a \(2 \times 3\) or a \(6
\times 7\) matrix by row reductions.<sup><a id="fnr.4" class="footref" href="#fn.4" role="doc-backlink">4</a></sup> Secondly, not all matrices have unique
solutions.<sup><a id="fnr.5" class="footref" href="#fn.5" role="doc-backlink">5</a></sup>  This
leaves us with the following questions:
</p>

<ul class="org-ul">
<li>Can we characterize the matrices for which it's easy to "read off"
their solutions?</li>
<li>What do these matrices look like if there are no solutions?</li>
<li>If there are infinitely many solutions, how do we characterize <i>all
possible</i> solutions?</li>
</ul>
</div>
</div>

<div id="outline-container-orgce02c93" class="outline-2">
<h2 id="orgce02c93">Echelon Form</h2>
<div class="outline-text-2" id="text-orgce02c93">
<p>
We'll actually introduce two kinds of matrices, echelon form matrices
and row-reduced echelon form (RREF) matrices (the reason will
hopefully become clear, but I ask that you suspend your disbelief for
now).  Row-reduced echelon form is <i>more restrictive</i> than just
echelon form; RREF matrices are also in echelon form, but not all
matrices in echelon form are RREF matrices.<sup><a id="fnr.6" class="footref" href="#fn.6" role="doc-backlink">6</a></sup>
</p>

<blockquote>
<p>
<b>Aside.</b> Echelon is not a name (as many people, including myself,
think when they first encounter this topic), it's a <a href="https://en.wikipedia.org/wiki/Echelon_formation">military term</a>
which describes a formation in which each successive unit in the
formation is behind and to one side of the unit in front of
it.
</p>

<a title="Pearson Scott Foresman, Public domain, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Echelon_1_(PSF).png"><img width="512" alt="Echelon 1 (PSF)" src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Echelon_1_%28PSF%29.png/512px-Echelon_1_%28PSF%29.png?20100315055206"></a>

<p>
This imagery is an incredibly useful visual pun for understanding how echelon forms look.
</p>
</blockquote>

<p>
First we have to set up some machinery.  This is just a math-y
formalization of exactly the description of the above aside.
</p>

<blockquote>
<p>
<b>Terminology.</b> The <b>leading entry</b> of a row in a matrix its first nonzero entry.
</p>
</blockquote>

<blockquote>
<p>
<b>Example.</b> The leading entries of each row in the following matrix are
underlined.  The third row does not have a leading entry.
</p>

\begin{bmatrix}
0 & \underline{1} & -1 & 2 \\
\underline{1} & 0 & 1 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & \underline{4} & 0
\end{bmatrix}
</blockquote>

<blockquote>
<p>
<b>Definition.</b> A matrix is in <b>echelon form</b> if
</p>
<ul class="org-ul">
<li>no all-zero rows appear above a row with a leading entry</li>
<li>if a row has a leading entry and it is not the first row, then it
appears to the right of the leading entry in the row above it</li>
</ul>
</blockquote>

<blockquote>
<p>
<b>Example.</b> The matrix from the previous example is not in echelon
form.  It has a all-zeros row which appears above a row with a leading
entry, and the leading entry of the second row appears to the left of
the leading entry in the first.  But it is equivalent to a matrix in
echelon form.  Applying the transformations \(R_1 \leftrightarrow R_2\)
and \(R_3 \leftrightarrow R_4\) gives us the matrix
</p>

\begin{bmatrix}
\underline{1} & 0 & 1 & 0 \\
0 & \underline{1} & -1 & 2 \\
0 & 0 & \underline{4} & 0 \\
0 & 0 & 0 & 0
\end{bmatrix}

<p>
which satisfies the property that the leading entries create a kind of
"cascading triangular" shape, with the all-zero rows at the end.
</p>
</blockquote>

<p>
The other visual pun that tends to be used to understand echelon form
is something like the following:
</p>

\begin{bmatrix}
0&\blacksquare&*&*&*&*&*&*&*&*\\
0&0&0&\blacksquare&*&*&*&*&*&*\\
0&0&0&0&\blacksquare&*&*&*&*&*\\
0&0&0&0&0&\blacksquare&*&*&*&*\\
0&0&0&0&0&0&0&0&\blacksquare&*\\
0&0&0&0&0&0&0&0&0&0\\
0&0&0&0&0&0&0&0&0&0\\
\end{bmatrix}

<p>
Here the \(\blacksquare\) entries represent nonzero entries and the \(*\)
entries represent any number whatsoever.  All the black squares appear
to the right and below the black squares above it (where applicable)
and the all-zero rows are at the bottom.  If a matrix has this general
"shape" then it is in echelon form.
</p>

<blockquote>
<p>
<b>Exercise.</b> Convert the following matrix into echlon form by a short
sequence of row reductions.
</p>

\begin{bmatrix}
0 & 0 & 0 & 0 & 2 & 1 \\
0 & 1 & 2 & 3 & 0 & 1 \\
1 & 1 & 1 & 1 & 1 & 1 \\
2 & 2 & 2 & 2 & 2 & 2
\end{bmatrix}
</blockquote>

<p>
Given an echelon form, its not yet easy to "read off" a solution if
there is one.  Take for example:
</p>

\begin{bmatrix}
1 & 4 & 3 & -3 \\
0 & 2 & 6 & -1 \\
0 & 0 & 3 & 1
\end{bmatrix}

<p>
Can you tell immediately that \((2, -1.5, 0.\overline{3})\) is a solution?
</p>

<p>
Where echelon forms are interesting is in the case of <i>inconsistent</i> systems.  Consider the simple 2D system
</p>

\begin{align*}
2x + 3y = 5 \\
-4x - 6y = 0 \\
\end{align*}

<p>
which has the augmented matrix
</p>

\begin{bmatrix}
2 & 3 & 5 \\
-4 & -6 & 0
\end{bmatrix}

<p>
which is row-equivalent to the matrix (by the operation \(R_2 \gets R_2 + 2R_1\))
</p>

\begin{bmatrix}
2 & 3 & 5 \\
0 & 0 & 10
\end{bmatrix}

<p>
which is in echelon-form (!), and which is represents the system
</p>

\begin{align*}
2x + 3y &= 5 \\
0 &= 5
\end{align*}

<p>
which is obviously inconsistent (\(0\) will never be equal to \(5\),
ever), which means we now know we no longer have to do any reductions
(which is great).
</p>

<p>
This turns out to be a general feature of echelon forms.
</p>

<blockquote>
<p>
<b>Theorem.</b> Let \(A\) be the augmented matrix of an inconsistent linear
system. If \(A \sim B\) and \(B\) is in echelon form, then the rightmost
column of \(B\) contains a leading entry.
</p>
</blockquote>

<p>
This leading entry represents the "obviously inconsistent" linear
equations which equates \(0\) to an nonzero value (like 5).  And its
important to read this correctly: <i>every</i> echelon form to which \(A\) is
equivalent has this property.  Since we're often interested in these
equivalent matrices, we'll call them, in a bit of terminological
abuse, the <b>echelon forms of A</b>.
</p>

<p>
Thus, we will think of the general echelon form as a "pit-stop" we can
make on our way to a RREF matrix (just as a reminder Gaussian
elimination is about converting a matrix to an equivalent RREF
matrix).
</p>

<p>
And if all we care about is characterizing the solutions, we can stop
here!<sup><a id="fnr.7" class="footref" href="#fn.7" role="doc-backlink">7</a></sup>
</p>
</div>
</div>

<div id="outline-container-orgfe6185c" class="outline-2">
<h2 id="orgfe6185c">Row-Reduced Echelon Form</h2>
<div class="outline-text-2" id="text-orgfe6185c">
<p>
Our next goal is to further restrict the notion of echelon form to a
form for which it is easy to "read off" solutions.  This time, we
start with the visual pun:
</p>

\begin{bmatrix}
0&1&*&0&0&0&*&*&0&*\\
0&0&0&1&0&0&*&*&0&*\\
0&0&0&0&1&0&*&*&0&*\\
0&0&0&0&0&1&*&*&0&*\\
0&0&0&0&0&0&0&0&1&*\\
0&0&0&0&0&0&0&0&0&0\\
0&0&0&0&0&0&0&0&0&0\\
\end{bmatrix}

<p>
Again, \(*\) entries can be any number whatsoever, so this form differs in that
</p>
<ul class="org-ul">
<li>leading entries are \(1\)</li>
<li>there are \(0\) entries <i>above</i> every leading entry (not just below)</li>
</ul>

<p>
And that's all there is to it.
</p>

<blockquote>
<p>
<b>Definition.</b> A matrix is in <b>row-reduced echelon form</b> (RREF) if
</p>
<ul class="org-ul">
<li>it is in echelon form</li>
<li>every leading entry is \(1\)</li>
<li>every column containing a leading entry has \(0\) entries everywhere else</li>
</ul>
</blockquote>

<blockquote>
<p>
<b>Example.</b> One answer to the exercise above is
</p>

\begin{align*}
\begin{bmatrix}
0 & 0 & 0 & 0 & 2 & 1 \\
0 & 1 & 2 & 3 & 0 & 1 \\
1 & 1 & 1 & 1 & 1 & 1 \\
2 & 2 & 2 & 2 & 2 & 2
\end{bmatrix}
\sim
\begin{bmatrix}
1 & 1 & 1 & 1 & 1 & 1 \\
0 & 1 & 2 & 3 & 0 & 1 \\
0 & 0 & 0 & 0 & 2 & 1 \\
0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}
\end{align*}

<p>
The matrix on the right is not quite in row-reduced echelon form.  The
leading entry of the third row is not \(1\) and there is a nonzero entry
above it. But via a sequence of row operations, we can get to the
matrix
</p>

\begin{bmatrix}
1 & 0 & -1 & -2 & 0 & -0.5 \\
0 & 1 & 2 & 3 & 0 & 1 \\
0 & 0 & 0 & 0 & 1 & 0.5 \\
0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}

<p>
which is an RREF matrix.
</p>
</blockquote>

<blockquote>
<p>
<b>Exercise.</b> Determine a sequence of row operations for the previous
 example.
</p>
</blockquote>

<p>
Before moving on, let's think about why RREF matrices are useful.
It's clear that the RREF matrix in the previous example does not have
a form like the one at the beginning of the chapter which represented a
unique solution.  If we take this matrix and write it as a system of
linear equations we get:
</p>

\begin{align*}
x_1 - x_3 - 2x_4 &= -0.5 \\
x_2 + 2x_3 + 3x_4 &= 1 \\
x_5 &= 0.5 \\
0 &= 0
\end{align*}

<p>
The third row has a familiar form, we get a value for \(x_5\) in any
solution to this system.  But in the case of the other variables,
we're not able to completely isolate them.  For example, \(x_1\) is not
a fixed value in any solution but has a relationship with \(x_3\) and
\(x_4\).  Same with \(x_2\).
</p>

<p>
<i>The (kind of magical) point:</i> All the leading entries in each row
<i>are</i> in fact isolated, in the sense that <b>they can be written in
terms of all the variables which are not in leading positions.</b>
</p>

<p>
In this example, if we isolate \(x_1\) and \(x_2\) (and ignore the
extraneous \(0 = 0\)) we get:
</p>

\begin{align*}
x_1 &= -0.5 + x_3 + 2x_4 \\
x_2 &= 1 - 2x_3 - 3x_4 \\
x_5 &= 0.5
\end{align*}

<p>
We interpret this as meaning that <b>no matter what values we give to
\(x_3\) and \(x_4\)</b>, once we fix those values, we can derive a solution
to the above system.
</p>

<p>
So \((-0.5, 1, 0, 0, 0.5)\) is a solution, but so is \((0, 0, 0.5, 0,
0.5)\).  In the first case, we've set \(x_3 = x_4 = 0\) and in the second
we've set \(x_3 = 0.5\) and \(x_4 = 0\).
</p>

<blockquote>
<p>
<b>Exercise.</b> Write down the system whose augmented matrix is
</p>

\begin{bmatrix}
0 & 0 & 0 & 0 & 2 & 1 \\
0 & 1 & 2 & 3 & 0 & 1 \\
1 & 1 & 1 & 1 & 1 & 1 \\
2 & 2 & 2 & 2 & 2 & 2
\end{bmatrix}

<p>
and verify that the above two solutions are, in fact, solutions to
this system.
</p>
</blockquote>

<p>
Again, I want to emphasize that this is a special feature of RREF
matrices.  If we instead had the matrix (which is not RREF)
</p>

\begin{bmatrix}
1 & 1 & -1 & -2 & 0 & -0.5 \\
0 & 1 & 2 & 3 & 0 & 1 \\
0 & 0 & 0 & 0 & 1 & 0.5 \\
0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}

<p>
then trying to isolate the leading terms as above would yield:
</p>

\begin{align*}
x_1 &= -0.5 - \underline{x_2} + x_3 + 2x_4 \\
\underline{x_2} &= 1 - 2x_3 - 3x_4 \\
x_5 &= 0.5
\end{align*}

<p>
and now there's a more complex relationship between \(x_1\) and \(x_2\)
because \(x_2\) appears on the LHS and RHS of equals signs.
</p>

<p>
The other important fact of RREF matrices is that <b>every matrix is
equivalent to (a unique) one.</b>
</p>

<blockquote>
<p>
<b>Theorem.</b>
</p>
<ul class="org-ul">
<li>No two distinct RREF matrix are equivalent.</li>
<li>Every matrix is equivalent to an RREF matrix.</li>
</ul>
</blockquote>

<blockquote>
<p>
<b>Exercise.</b> Convince yourself that this implies every matrix is
 equivalent to exactly one RREF matrix.
</p>
</blockquote>

<p>
What's more, Sympy has a convenient function for getting the unique RREF of a matrix!
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #a020f0;">from</span> sympy <span style="color: #a020f0;">import</span> *
<span style="color: #a0522d;">A</span> = Matrix([
    [1, 1, 1, 1],
    [0, -2, 1, -1],
    [3, 1, -3, 3]
])

pprint(A.rref())
<span style="color: #483d8b;">print</span>()
pprint(A.rref()[0])
</pre>
</div>

<pre class="example" id="orgfd43aac">
⎛⎡1  0  0  5/7 ⎤           ⎞
⎜⎢             ⎥           ⎟
⎜⎢0  1  0  3/7 ⎥, (0, 1, 2)⎟
⎜⎢             ⎥           ⎟
⎝⎣0  0  1  -1/7⎦           ⎠

⎡1  0  0  5/7 ⎤
⎢             ⎥
⎢0  1  0  3/7 ⎥
⎢             ⎥
⎣0  0  1  -1/7⎦
</pre>

<p>
The second argument argument holds the indices of the pivot columns of
the matrix.  We won't use these for now, but they may be useful to
have in the future.  Just remember that if you want to use <code>a.rref()</code>
to <b>grab the first element</b> as in <code>a.rref()[0]</code>.
</p>
</div>
</div>

<div id="outline-container-orge3dcedd" class="outline-2">
<h2 id="orge3dcedd">General form solutions</h2>
<div class="outline-text-2" id="text-orge3dcedd">
<p>
Taking stock, solving a general system of linear equations will follow this outline:
</p>
<ul class="org-ul">
<li>Write your system as an augmented matrix</li>
<li>Use Gaussian elimination to convert this matrix into an equivalent RREF matrix</li>
<li><i>Read off the solution from the RREF matrix</i><sup><a id="fnr.8" class="footref" href="#fn.8" role="doc-backlink">8</a></sup></li>
</ul>

<p>
Our goal now is to deal with this last step, formalizing the process
from the end of the last section.  We begin with some terminology.
</p>

<blockquote>
<p>
<b>Terminology.</b> The position of a leading entry in an echelon form of a
matrix is called a <b>pivot position</b>.  A column with a pivot position
is called a <b>pivot column</b>.
</p>
</blockquote>

<p>
We won't worry too much about <i>why</i> they're called pivot positions,
suffices to say for now that it has to do with some of the
nitty-gritty details of Gaussian elimination.
</p>

<p>
Note also that we're interested in the pivot positions/columns of the
<i>original</i> matrix, not just a matrix in echelon form.
</p>

<blockquote>
<p>
<b>Example.</b> The pivot positions of both equivalent matrices are
underlined.
</p>

\begin{align*}
\begin{bmatrix}
\underline{0} & 0 & 0 & 0 & 2 & 1 \\
0 & \underline{1} & 2 & 3 & 0 & 1 \\
1 & 1 & 1 & 1 & \underline{1} & 1 \\
2 & 2 & 2 & 2 & 2 & 2
\end{bmatrix}
\sim
\begin{bmatrix}
\underline{1} & 1 & 1 & 1 & 1 & 1 \\
0 & \underline{1} & 2 & 3 & 0 & 1 \\
0 & 0 & 0 & 0 & \underline{2} & 1 \\
0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}
\end{align*}
</blockquote>

<p>
We want to have a uniform way of writing down the solution sets of a
given linear system.  There are a couple ways to do this, we'll use
what's called <b>general form</b> also sometimes called <b>parametric form</b>.
</p>

<blockquote>
<p>
<b>Warning.</b> In what follows, we assume we're working with an augmented
 matrix.  If the matrix is not the augmented matrix of a system, then
 the terminology doesn't make sense.
</p>
</blockquote>

<p>
Writing a general form solution is about isolating a collection of
variables (called <b>basic</b> variables) and writing them in terms of the
remaining variables (called <b>free</b> variables, becuase we're "free" to
choose their values when we want to find a specific solution to a
system).  It's a way of describing not just single solutions, but
solution sets "paramatrized" by choices of values for a collection of
varaibles.  With the terminology we have, we can formalize this a bit
(and introduce more terminology).
</p>

<blockquote>
<p>
<b>Terminology.</b> A variable is <b>basic</b> if its corresponding column is a
pivot column. Otherwise it is called <b>free</b>.
</p>
</blockquote>

<blockquote>
<p>
<b>Example.</b> In the previous example, the basic variables are \(x_1\),
 \(x_2\), and \(x_5\) since the first, third, and fifth columns have
 leading entries. The remaining variables (\(x_3\) and \(x_4\)) are free
 variables.
</p>
</blockquote>

<p>
At this point, there isn't much left to do but state everything we've
said up to now in a concise way (and get lots of practice with the
concepts).
</p>

<blockquote>
<p>
<b>HOW-TO.</b> <i>Writing a general-form solution from an RREF matrix</i>
</p>
<ol class="org-ol">
<li>Write the RREF as a system of linear equations.</li>
<li>Drop any extraneous \(0 = 0\) equations. If the system includes the
equation \(0 = 1\), then just write <b>no solution</b>. Otherwise
continue.</li>
<li>Isolate the leading terms of each equation, writing each leading term
as an equation of the free variables.</li>
<li>Write <b>\(x_i\) is free</b> for the remaining variables.<sup><a id="fnr.9" class="footref" href="#fn.9" role="doc-backlink">9</a></sup></li>
</ol>
</blockquote>

<blockquote>
<p>
<b>Example.</b> We come back to this RREF matrix:
</p>

\begin{bmatrix}
1 & 1 & -1 & -2 & 0 & -0.5 \\
0 & 1 & 2 & 3 & 0 & 1 \\
0 & 0 & 0 & 0 & 1 & 0.5 \\
0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}

<ol class="org-ol">
<li><p>
We write this as the system:
</p>
\begin{align*}
x_1 - x_3 - 2x_4 &= -0.5 \\
x_2 + 2x_3 + 3x_4 &= 1 \\
x_5 &= 0.5 \\
0 &= 0
\end{align*}</li>
<li><p>
We drop the extranous \(0 = 0\) equation:
</p>
\begin{align*}
x_1 - x_3 - 2x_4 &= -0.5 \\
x_2 + 2x_3 + 3x_4 &= 1 \\
x_5 &= 0.5 \\
\end{align*}</li>
<li><p>
We isolate the leading terms in each row:
</p>
\begin{align*}
x_1 &= -0.5 + x_3 + 2x_4 \\
x_2 &= 1 - 2x_3 - 3x_4 \\
x_5 &= 0.5
\end{align*}</li>
<li><p>
We add lines which tell us which variables are free (which variables on which \(x_1\), \(x_2\), and \(x_5\) depend:
</p>
\begin{align*}
x_1 &= -0.5 + x_3 + 2x_4 \\
x_2 &= 1 - 2x_3 - 3x_4 \\
x_3 &\quad \text{is free} \\
x_4 &\quad \text{is free} \\
x_5 &= 0.5
\end{align*}</li>
</ol>
</blockquote>

<p>
Again, we can get a <i>specific</i> solution by choosing values for the
free variables (\(x_3\) and \(x_4\)) and calculating the values of the
basic variables.
</p>

<blockquote>
<p>
<b>Example.</b> If we take \(x_3 = 1\) and \(x_4 = 1\), then we get the solution:
</p>
\begin{align*}
x_1 &= -0.5 + 1 + 2 = 2.5 \\
x_2 &= 1 - 2 - 3 = -4 \\
x_3 &= 1 \\
x_4 &= 1 \\
x_5 &= 0.5
\end{align*}
<p>
or \((-3.5, -2, 1, 1, 0.5)\) written as a point in \(\mathbb R^5\).
</p>
</blockquote>

<blockquote>
<p>
<b>Exercise.</b> Write the general-form solution for the following RREF matrix (and convince yourself that it is, in fact, RREF)
</p>

\begin{bmatrix}
1 & 2 & 0 & -2 & 4 \\
0 & 0 & 1 & 3 & 5 \\
0 & 0 & 0 & 0 & 0
\end{bmatrix}

<p>
Then write three distinct solutions to this system by choosing particular values for the free variables.
</p>
</blockquote>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">And since the resultant matrix
is row-equivalent to the starting matrix, these solutions are
<i>exactly</i> the solutions to the starting linear system.</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">"Solving" is in quotes because this class
represents, in essence, "trivial" linear systems.</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3" role="doc-backlink">3</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">This matrix, call the \(n
\times n\) <b>identity matrix</b>, will become very familiar to us.</p></div></div>

<div class="footdef"><sup><a id="fn.4" class="footnum" href="#fnr.4" role="doc-backlink">4</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">It may be obvious, but it's
worth noting explicitly that the row operations <i>never</i> change the
shape of the matrix</p></div></div>

<div class="footdef"><sup><a id="fn.5" class="footnum" href="#fnr.5" role="doc-backlink">5</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">Perhaps less obvious, this implies that a system with a
\(2 \times 7\) augmented matrix cannot have a unique solution.</p></div></div>

<div class="footdef"><sup><a id="fn.6" class="footnum" href="#fnr.6" role="doc-backlink">6</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">We'll also often write
"reduced echelon form" (dropping the "row-" part).</p></div></div>

<div class="footdef"><sup><a id="fn.7" class="footnum" href="#fnr.7" role="doc-backlink">7</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">We often still want an RREF matrix, even if the matrix
represents an inconsistent system, it depends on the application.</p></div></div>

<div class="footdef"><sup><a id="fn.8" class="footnum" href="#fnr.8" role="doc-backlink">8</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">Again, in the case of inconsistent systems, Gaussian elimination, depending on the implementation, may stop at just echelon form because inconsistency can already be determined.</p></div></div>

<div class="footdef"><sup><a id="fn.9" class="footnum" href="#fnr.9" role="doc-backlink">9</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">Typically we maintain the order of variables in a general-form solutions, so we would usually write <b>\(x_2\) is free</b> on the second line of a general-form solution.</p></div></div>


</div>
</div></div>
</body>
</html>
